{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York City's Taxi Fare Dataset.\n",
    "\n",
    "Performing Exploratory Data Analysis on NYC Taxi Fare Dataset.\n",
    "https://www.kaggle.com/datasets/diishasiing/revenue-for-cab-drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Necessary Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TaxiFareDataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the Dimensionality and Attribute Types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The Dimensionality of Dataset: {data.shape}')\n",
    "print('\\033[33mThe Attributes of Dataset and types\\033[0m')\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Characteristics of Numerical Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions to represent the Data.\n",
    "data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique Values and their count in the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attr = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'store_and_fwd_flag']\n",
    "for col in cat_attr:\n",
    "    print(f'\\033[33mNo. of Unique Values for {col}\\033[0m : {len(data[col].unique())}')\n",
    "    print(f'Unique Values : {data[col].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Demographics of the Dataset we can see that there is a need for Data Preprocessing as: -  \n",
    "1. There Exists **NULL Values** in the Dataset for certain records\n",
    "2. There might be chance of Duplicate Records as well.\n",
    "3. Certain Attributes like **trip_distance** has negative values where as distance is always a positive unit, **Amount**, **tip_amount**, etc., also contains negative value as minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Null Values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Identifying NULL Values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way to find NULL Values.\n",
    "\n",
    "missing_data = data.isnull()\n",
    "\n",
    "for col in missing_data.columns.values.tolist():\n",
    "    print(f'\\033[33m{col}\\033[0m')\n",
    "    print(missing_data[col].value_counts())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the NULL Values are: 1. VendorID, 2. passenger_count, 3. RatecodeID, 4. store_and_fwd_flag, 5. payment_type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Filling up or Removing NULL Value Records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['VendorID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing the Distribution of the VendorID Attribute.\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Distribution of VendorID')\n",
    "sns.histplot(data['VendorID'], kde=True, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Data Distribution, and from the Dataset Description about **VendorID** Column, it describes the unique identifier for the taxi vendor or service provider. So, the records with null values in VendorID needs to be dropped as the future analysis comaprision between two types of providers is significant which gets changed if we replace the null values with value '2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['VendorID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing the Distribution of the Attributes\n",
    "cols = ['passenger_count', 'RatecodeID', 'store_and_fwd_flag', 'payment_type']\n",
    "\n",
    "for col in cols:\n",
    "    print(f'\\033[33mThe Unique Values of the {col} are of\\033[0m: {data[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring categorical columns to string type for plotting\n",
    "data['store_and_fwd_flag'] = data['store_and_fwd_flag'].astype(str)\n",
    "data['payment_type'] = data['payment_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Distributions of the Attributes\n",
    "\n",
    "# Setting up subplots\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, col in enumerate(cols, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    \n",
    "    # Use histplot for numerical data, countplot for categorical\n",
    "    if data[col].dtype in ['int64', 'float64']:\n",
    "        sns.histplot(data[col], bins=20, kde=True)\n",
    "    else:\n",
    "        sns.countplot(x=data[col], order=data[col].value_counts().index)\n",
    "    \n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the attributes **passenger_count**, are highly skewed data with continuous values from 0 to 9. we can choose median to fill the missing values than the mean type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['passenger_count'].fillna(data['passenger_count'].median().astype(float), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remaining the attributes **RatecodeID, Store_and_fwd_flag, Payment_type** are all categorical data, and mode is optimal method to replace the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['RatecodeID', 'store_and_fwd_flag', 'payment_type']\n",
    "\n",
    "for col in cols:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Duplicated Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Outlier Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying and Handling the Outliers present in the Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Identifying the Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the Numerical Columns for Outlier Detection\n",
    "\n",
    "num_cols = ['passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax', \n",
    "            'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', \n",
    "            'congestion_surcharge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating box plots for each numerical column\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(4, 3, i)  # Adjust rows & columns as needed\n",
    "    sns.boxplot(x=data[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative values present in the Attributes of **trip_distance, fare_amount, tip_amount, tolls_amount, total_amount** since these attributes cannot possess the neagtive values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence removing them is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert relevant columns to numeric (forcing errors='coerce' will replace non-numeric values with NaN)\n",
    "cols_to_check = ['fare_amount', 'tip_amount', 'total_amount', 'trip_distance', 'tolls_amount']\n",
    "data[cols_to_check] = data[cols_to_check].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Identify rows with negative values\n",
    "negative_values = data[\n",
    "    (data['fare_amount'] < 0) | \n",
    "    (data['tip_amount'] < 0) | \n",
    "    (data['total_amount'] < 0) | \n",
    "    (data['trip_distance'] < 0) | \n",
    "    (data['tolls_amount'] < 0)\n",
    "]\n",
    "\n",
    "# Print the count of negative values\n",
    "print(\"Negative value counts:\")\n",
    "print((data[cols_to_check] < 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with negative values if they are errors\n",
    "data = data[\n",
    "    (data['fare_amount'] >= 0) & \n",
    "    (data['tip_amount'] >= 0) & \n",
    "    (data['total_amount'] >= 0) & \n",
    "    (data['trip_distance'] >= 0) & \n",
    "    (data['tolls_amount'] >= 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating box plots for each numerical column\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(4, 3, i)  # Adjust rows & columns as needed\n",
    "    sns.boxplot(x=data[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the IQR(Inter Quartile Range) based filtering, Z-Score Filtering, and Log Transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers based on IQR\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Function to remove outliers based on Z-score\n",
    "def remove_outliers_zscore(df, column, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(df[column], nan_policy='omit'))  # 'omit' to handle NaN values\n",
    "    return df[z_scores < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply IQR filtering to selected columns\n",
    "columns_to_filter = ['trip_distance', 'fare_amount', 'tip_amount']\n",
    "for col in columns_to_filter:\n",
    "    data = remove_outliers_iqr(data, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Z-score filtering\n",
    "for col in columns_to_filter:\n",
    "    data = remove_outliers_zscore(data, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating box plots for each numerical column\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(4, 3, i)  # Adjust rows & columns as needed\n",
    "    sns.boxplot(x=data[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers have been significantly reduced and can be even scaled down after performing the data normalization task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a small constant to avoid log(0) issues\n",
    "data['trip_distance_log'] = np.log1p(data['trip_distance'])\n",
    "data['fare_amount_log'] = np.log1p(data['fare_amount'])\n",
    "data['tip_amount_log'] = np.log1p(data['tip_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ['trip_distance_log', 'fare_amount_log', 'tip_amount_log']\n",
    "\n",
    "# Creating box plots for each numerical column\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(temp, 1):\n",
    "    plt.subplot(4, 3, i)  # Adjust rows & columns as needed\n",
    "    sns.boxplot(x=data[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['trip_distance'] = data['trip_distance_log']\n",
    "data['fare_amount'] = data['fare_amount_log']\n",
    "data['tip_amount'] = data['tip_amount_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Standardaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime format (fixing the issue)\n",
    "data['tpep_pickup_datetime'] = pd.to_datetime(data['tpep_pickup_datetime'], errors='coerce')\n",
    "data['tpep_dropoff_datetime'] = pd.to_datetime(data['tpep_dropoff_datetime'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into separate columns for all rows\n",
    "data['pickup_date'] = data['tpep_pickup_datetime'].dt.date\n",
    "data['pickup_time'] = data['tpep_pickup_datetime'].dt.time\n",
    "\n",
    "data['dropoff_date'] = data['tpep_dropoff_datetime'].dt.date\n",
    "data['dropoff_time'] = data['tpep_dropoff_datetime'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop({'tpep_pickup_datetime', 'tpep_dropoff_datetime'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop({'trip_distance_log', 'fare_amount_log', 'tip_amount_log'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('TaxiFareCleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bivariate Analysis Graphs\n",
    "\n",
    "Relationship between Two Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=data['trip_distance'], y=data['fare_amount'], alpha=0.5)\n",
    "plt.xlabel(\"Trip Distance (miles)\")\n",
    "plt.ylabel(\"Fare Amount ($)\")\n",
    "plt.title(\"Trip Distance vs Fare Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=data['trip_distance'], y=data['total_amount'], alpha=0.5)\n",
    "plt.xlabel(\"Trip Distance (miles)\")\n",
    "plt.ylabel(\"Total Amount ($)\")\n",
    "plt.title(\"Trip Distance vs Total Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=data['trip_distance'], y=data['tip_amount'], alpha=0.5)\n",
    "plt.xlabel(\"Trip Distance (miles)\")\n",
    "plt.ylabel(\"Tip Amount($)\")\n",
    "plt.title(\"Trip Distance vs Tip Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Correlation Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 11))\n",
    "sns.heatmap(data.select_dtypes(include=[\"number\"]).corr(), annot=True, cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Time - Based Visualization\n",
    "\n",
    "To check trip trends by hour of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=data['pickup_time'], palette=\"viridis\")\n",
    "plt.xlabel(\"Hour of the Day\")\n",
    "plt.ylabel(\"Trip Count\")\n",
    "plt.title(\"Number of Trips by Hour\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Interative Maps using Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(data, x=\"payment_type\", title=\"Trip Count by Payment Type\", color=\"payment_type\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
